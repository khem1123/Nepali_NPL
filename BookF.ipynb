{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afc6c0b-b002-448c-995b-60645486f4a0",
   "metadata": {},
   "source": [
    "# Nepali Text Analysis Using Python\n",
    "\n",
    "This notebook demonstrates the natural language processing of text written in Nepali. \n",
    "In this code I analyze the book titled \"рдлрд░рдХ рдЖрдХрд╛рд░, рдлрд░рдХ рдЖрдпрд╛рдо - рдкреБрдирд░реНрдмрд╛рд╕рдкрдЫрд┐рдХрд╛ рднреВрдЯрд╛рдиреА рдиреЗрдкрд╛рд▓реА рдХрд╡рд┐рддрд╛\" published by рд╕рд╛рд╣рд┐рддреНрдп рдкрд░рд┐рд╖рдж рднреВрдЯрд╛рди. \n",
    "The book is a collection of poems written by Bhutanese writers from XXX.YYY.\n",
    "\n",
    "Some quantitative analyses in this code require contextual knowledge about Bhutanese Nepali writers, which is included in Journal Paper XXX. \n",
    "This notebook should be used to understand the technical method used for analysis and can be extended to any Nepali text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf5546-9ee5-4bc2-a174-ccecef8b58b3",
   "metadata": {},
   "source": [
    "## Load the library\n",
    "As the digital copy of the book is in MS -Word format.\n",
    " The famous Pandas are used to eat bamboo and to make Tables! I use matplotlib for plotting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffa6e51-eef9-4c9d-a392-97c6cd9d2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.figure import Figure as figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db834f-e88b-4651-8929-9381ec790e34",
   "metadata": {},
   "source": [
    "## Load the Document\n",
    "I load the document, read the Poem titles defined in the word as Heading 4, and extract Normal text under each heading as the \"poems.\" Writer Names are defined with MS word Word style Name \"Chapter Title,\" so I use that filter to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4348cc8-927f-43df-90b0-2c9677d1f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(\"PoetryCollection2.docx\")\n",
    "headings = []\n",
    "texts = []\n",
    "para = []\n",
    "for paragraph in document.paragraphs:\n",
    "    if paragraph.style.name.startswith(\"Heading 4\"):\n",
    "        if headings:\n",
    "            texts.append(para)\n",
    "        headings.append(paragraph.text)\n",
    "        para = []\n",
    "    elif paragraph.style.name == \"Normal\":\n",
    "        para.append(paragraph.text)\n",
    "if para or len(headings)>len(texts):\n",
    "    texts.append(texts.append(para))\n",
    "    \n",
    "Writers=[]\n",
    "for section  in document.paragraphs:\n",
    "    if section.style.name.startswith(\"Chapter Title\"):\n",
    "        Writers.append(section.text)\n",
    "        if '\\n' in Writers: Writers.remove('\\n')\n",
    "        \n",
    "h1=[]\n",
    "t1=[]\n",
    "for h, t in zip(headings, texts):\n",
    "    h1.append(h)\n",
    "    t1.append(t) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a89e4-0eec-47f2-8fc0-97ff2e273f10",
   "metadata": {},
   "source": [
    "#### Create a Table for extracted values\n",
    "Now I put writers, Poem heading, and all text in a table called df! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b73eff4-8284-4822-a8d3-aa59aefa9463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Writers</th>\n",
       "      <th>Poems</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>рдЕрдЬрд┐рдд рд░реБрдкрд╛рдмреБрдЩреН</td>\n",
       "      <td>рдХрд╕рд░реА рдмрд╛рдБрдЪреНрдиреБ рднрдПрдХреЛ рдЫ ?</td>\n",
       "      <td>[рдо рдд рдпрд╕реНрддреЛ рдард╛рдЙрдБрдорд╛ рдЫреБ, рдЬрд╣рд╛рдБ, рдорд╛рдиреНрдЫреЗрд╣рд░реВрдХреЛ рдареЗрд▓рдордареЗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>рдЕрдзрд┐рдХрд╛рд░реА рдХрд╛рдиреНрдЫреЛ (рдкрд░рдорд╛рдирдиреНрдж )</td>\n",
       "      <td>рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕рдмреБрдХ рд╣реЛ</td>\n",
       "      <td>[рдмреЛрд▓реНрджрд╛ рд╣реЗрд░реНрди рд╣реБрдиреЗ рдмрд╕реЗ рдкрд░рдкрд░реИ рдХрд╕реНрд▓реЗ рдмрдирд╛рдпреЛ рдХреБрдиреА,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>рдЕрдирдиреНрдд рдЖрдЪрд╛рд░реНрдп</td>\n",
       "      <td>рдЖрдорд╛рдХреЛ рдкрддреНрд░</td>\n",
       "      <td>[рдорд╛рддреГрд╡рд╛рддреНрд╕рд▓реНрдпрдмрд╛рдЯ-, рдо рдпрд╣рд╛рдБрд╕рдореНрдо рдЖрдЗрдкреБрдЧреНрджрд╛, рдХрд╛рд▓реЛ рд░...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>рдЕрдмрд┐рдмрд╛рдмреБ рдЕрдзрд┐рдХрд╛рд░реА</td>\n",
       "      <td>рдкрд╛рд░рдкрд╛рдЪреБрдХреЗ</td>\n",
       "      <td>[рдЖ-рдЖрдлреНрдиреВ рдШрдордгреНрдбрд▓реЗ рд╣рд╛рдореНрд░реЛ рдмрд╛рдЯреЛ рдЫреБрдЯреНрдЯрд┐рдпреЛ,, рд╕рдБрдЧреИ рдЬ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>рдЕрдореНрдмрд┐рдХрд╛рдкреНрд░рд╕рд╛рдж рджреБрд▓рд╛рд▓</td>\n",
       "      <td>рд╕рдореНрдЭрдиреНрдЫреБ рд╕рдореНрдЭрдиреНрдЫреБ рд╣реИ</td>\n",
       "      <td>[рдЬрд▓рдврдХрд╛ рдЕрдирд┐ рдмрдЧреНрдЫ рдзрдирд╕рд┐рд░рд┐ рдирджреА рдкрд╢реНрдЪрд┐рдо рддрдерд╛ рдкреВрд░реНрд╡рдорд╛,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Writers                  Poems  \\\n",
       "0               рдЕрдЬрд┐рдд рд░реБрдкрд╛рдмреБрдЩреН  рдХрд╕рд░реА рдмрд╛рдБрдЪреНрдиреБ рднрдПрдХреЛ рдЫ ?   \n",
       "1  рдЕрдзрд┐рдХрд╛рд░реА рдХрд╛рдиреНрдЫреЛ (рдкрд░рдорд╛рдирдиреНрдж )     рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕рдмреБрдХ рд╣реЛ   \n",
       "2                рдЕрдирдиреНрдд рдЖрдЪрд╛рд░реНрдп             рдЖрдорд╛рдХреЛ рдкрддреНрд░   \n",
       "3             рдЕрдмрд┐рдмрд╛рдмреБ рдЕрдзрд┐рдХрд╛рд░реА              рдкрд╛рд░рдкрд╛рдЪреБрдХреЗ   \n",
       "4         рдЕрдореНрдмрд┐рдХрд╛рдкреНрд░рд╕рд╛рдж рджреБрд▓рд╛рд▓   рд╕рдореНрдЭрдиреНрдЫреБ рд╕рдореНрдЭрдиреНрдЫреБ рд╣реИ   \n",
       "\n",
       "                                                Text  \n",
       "0  [рдо рдд рдпрд╕реНрддреЛ рдард╛рдЙрдБрдорд╛ рдЫреБ, рдЬрд╣рд╛рдБ, рдорд╛рдиреНрдЫреЗрд╣рд░реВрдХреЛ рдареЗрд▓рдордареЗ...  \n",
       "1  [рдмреЛрд▓реНрджрд╛ рд╣реЗрд░реНрди рд╣реБрдиреЗ рдмрд╕реЗ рдкрд░рдкрд░реИ рдХрд╕реНрд▓реЗ рдмрдирд╛рдпреЛ рдХреБрдиреА,...  \n",
       "2  [рдорд╛рддреГрд╡рд╛рддреНрд╕рд▓реНрдпрдмрд╛рдЯ-, рдо рдпрд╣рд╛рдБрд╕рдореНрдо рдЖрдЗрдкреБрдЧреНрджрд╛, рдХрд╛рд▓реЛ рд░...  \n",
       "3  [рдЖ-рдЖрдлреНрдиреВ рдШрдордгреНрдбрд▓реЗ рд╣рд╛рдореНрд░реЛ рдмрд╛рдЯреЛ рдЫреБрдЯреНрдЯрд┐рдпреЛ,, рд╕рдБрдЧреИ рдЬ...  \n",
       "4  [рдЬрд▓рдврдХрд╛ рдЕрдирд┐ рдмрдЧреНрдЫ рдзрдирд╕рд┐рд░рд┐ рдирджреА рдкрд╢реНрдЪрд┐рдо рддрдерд╛ рдкреВрд░реНрд╡рдорд╛,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"Writers\",\"Poems\",\"Text\"])\n",
    "df[\"Writers\"]=Writers\n",
    "df[\"Poems\"]=h1\n",
    "df[\"Text\"]=t1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93685a29-978a-440c-8c04-53b84a737370",
   "metadata": {},
   "source": [
    "Let us see what the text looks like. Here I randomly print the second and the 88th  poem from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a29052-408a-49e9-9aad-2974d6ebf1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['рдорд╛рддреГрд╡рд╛рддреНрд╕рд▓реНрдпрдмрд╛рдЯ-',\n",
       " 'рдо рдпрд╣рд╛рдБрд╕рдореНрдо рдЖрдЗрдкреБрдЧреНрджрд╛',\n",
       " 'рдХрд╛рд▓реЛ рд░рд╛рддрдорд╛,',\n",
       " 'рдореИрдБрд▓реЗ рдПрдЙрдЯрд╛ рдкрддреНрд░ рдкреНрд░рд╛рдкреНрдд рдЧрд░реЗрдБ тАУ',\n",
       " 'тАЬрдордмрд╛рдЯ рдЫреБрдЯрд╛рдПрд░ рд▓рдЧреЗрдкрдЫрд┐',\n",
       " 'рд╕рджреИрд╡ рд╢рд╛рдиреНрддрд┐ рд░рд╣реЗрди рдордорд╛',\n",
       " 'рдореЗрд░реЛ рд╡рд░рд┐рдкрд░рд┐ ',\n",
       " 'рдЦрдЬреБрд░рд╛ рд░ рдмрд┐рдЪреНрдЫреАрд╣рд░реВ рджреЗрдЦреНрдЫреБ',\n",
       " 'рд╕рд░реНрдкрд╣рд░реВ рдорд▓рд╛рдИ рдЯреЛрдХреНрди рдЖрдЙрдБрдЫрдиреН',\n",
       " 'рдмрд▓рд┐рдиреНрджреНрд░ рдЖрдБрд╕реБ',\n",
       " 'рдЕрд╕рд┐рдд рджреЗрд╣ рд▓рд┐рдПрд░',\n",
       " 'рдо рддрд┐рдореАрд▓рд╛рдИ рдкрд░реНрдЦрдиреНрдЫреБ',\n",
       " 'рдпрджрд┐ рд╕рдХрд┐рдиреНрдЫ рднрдиреЗ',\n",
       " 'рдореЗрд░реЛ рдЕрдорд┐рд▓реЛ рдордирдХреЛ рдмрд╛рдЯреЛ рднрдПрд░ рдЖрдК',\n",
       " 'рддреНрдпреЛ рд╕рдВрд╕рд╛рд░рдорд╛',\n",
       " 'рд╕рдмреИ рдХреБрд░рд╛рд╣рд░реВ рдкрд╛рдЙрдиреЗрдЫреМрдБ',\n",
       " 'рд░рд╛рддрдкрдЫрд┐ рджрд┐рди рд╣реБрдиреНрдЫ',\n",
       " 'рдо рддреНрдпреЛ рдХреБрд░рд┐рд░рд╣реЗрдХреЛ рдЫреБ редтАЭ',\n",
       " 'рдЖрдорд╛рдХреЛ рдкрддреНрд░ рдкрдврд┐рд╕рдХреЗрдкрдЫрд┐',\n",
       " 'рдореЗрд░рд╛ рдЖрдБрдЦрд╛рдмрд╛рдЯ рдЖрдБрд╕реБ рдЭрд░реЗрд░',\n",
       " 'рдкрддреНрд░рдХреЛ тАЬрддрд┐рдореА рдЖрдКтАЭ',\n",
       " 'рд╢рдмреНрдж рдореЗрдЯрд┐рдпреЛ ред',\n",
       " 'рдореЗрд░реЛ рд╣рд╛рддрдмрд╛рдЯ рдкрддреНрд░ рдЭрд░реН\\u200dрдпреЛ',\n",
       " 'рдЖтАжрдорд╛тАж..рдХреЛтАж.рдкрддреНрд░тАжтАж!!! \\n',\n",
       " 'рдкреЗрдиреНрд╕рд┐рд▓рднреЗрдирд┐рдпрд╛, рдЕрдореЗрд░рд┐рдХрд╛  ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b510f8-1f52-418a-ad4f-2ee548526e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['рд╣реЛ рдо рд╣рдЬрд╛рд░реМрдБ рдЪреЛрдЯрд┐ рдкрдЯрдХ рдкрдЯрдХ рд▓реБрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдЕрдирд┐ рд╕рдпреМрдБ рдкрдЯрдХ рдардЧрд┐рдирд╕рдореНрдо рдардЧрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рднрд┐рдбрдорд╛, рдЧрдиреНрджрд╛рдЧрдиреНрджреИ рдЧрдиреНрддреАрдорд╛ рд╣рд░рд╛рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдмреЛрд▓реНрджрд╛рдмреЛрд▓реНрджреИ рдХреИрдпреМрдБ рдкрдЯрдХ рдмреЛрд▓реА рднрд╛рд╕рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдмрд╕реНрджрд╛рдмрд╕реНрджреИ рдмрд╕реЗрдХреИ рдард╛рдЙрдБрдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рд░реЛрдЧ, рднреЛрдХ рдЕрдирд┐ рдирд╛рдЩреНрдЧреЛ рд╢рд░реАрд░ рдмреБрдЭреЗрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рджреЗрд╢рдорд╛ рд╕реБрдирдЧрд╛рднрд╛ рд░ рд╕реБрдирд╛рдЦрд░реА рд░реЛрдкреНрди рдЦреЛрдЬреНрджреИ рдЧрд░реНрджрд╛ рдорди рдлрд╛рдЯреЗрдХреЛ рдорд╛рдиреНрдЫреЗ ред',\n",
       " '',\n",
       " 'рд╕рд╛рдБрдЪреНрдЪреИ рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдЧрд╛рдБрд╕, рдмрд╛рд╕  рд░ рдХрдкрд╛рд╕рдХреЛ рднрд┐рдЦ рддрд┐рдореАрд╕рдБрдЧ рдорд╛рдЧреНрдиреЗ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдкрдХреНрдХрд╛ рд╣реЛ, рдзреЗрд░реИрд╕рдБрдЧ рд╣рд╛рдд рдлрд┐рдБрдЬрд╛рдИ  рдорд╛рдЧреА рдЦрд╛рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рд╣реЛ, рдо рдд рдЕрд╕рдЬрд┐рд▓реЛ рд╕рдордп рд░ рдкрд░рд┐рд╡реЗрд╢рдорд╛ рднрд┐рдЬреЗрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдкреАрдбрд╛, рдорд╛рдпрд╛ рдордорддрд╛ рдЕрдирд┐ рджреБрдГрдЦ рд╕реБрдЦ рд╕рдмреИ рдмреЛрдХреЗрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рддрд░, рдЕрдЭреИ рдкрдирд┐ рдЖрдХрд╛рд╢ рдЫреБрдиреЗ рд▓рдХреНрд╖реНрдп рдмреЛрдХреЗрд░ рдЕрдШрд┐ рдмрдвреЗрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рджреЗрд╢рдорд╛ рдкрд░рд┐рд╡рд░реНрддрди рд╣реЗрд░реНрдиреЗ, рднрд┐рдЦрдХреЛ рдЛрдг рддрд┐рд░реНрдиреЗ рдЬреЛрд╕ рднрдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рдкрдЫрд╛рдбрд┐рдмрд╛рдЯ рдЫреБрд░рд╛ рд░реЛрдкреНрдиреЗ рд╕рд╛рдереАрднрдиреНрджрд╛ рдЕрдЧрд╛рдбрд┐рдмрд╛рдЯ',\n",
       " 'рдЫреБрд░рд╛ рд░реЛрдкреНрдиреЗ рджреБрд╕реНрдорди рдкреНрдпрд╛рд░реЛ рдорд╛рдиреНрдиреЗ рдорд╛рдиреНрдЫреЗред',\n",
       " 'рддреНрдпрд╕реИрд▓реЗ рд╢рд╛рди рдирджреЗрдЦрд╛рдК рддрд┐рдореА, рдо рдмрд┐рдирд╛ рдХрд╕реБрд░рдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ',\n",
       " 'рд╕рд╛рдБрдЪреНрдЪреИ рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ ред',\n",
       " '\\n',\n",
       " 'рдХреЗрдиреНрдЯрдХреА, рдЕрдореЗрд░рд┐рдХрд╛']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf600e-f28b-4507-be1d-fe9787d4c679",
   "metadata": {},
   "source": [
    "As you can see, the poems are formatted and read differently. In the first printed Text (Poem 1)\n",
    "There are a few Unicode characters and a few blank lines. Each element of the Text should be a list containing a line from a poem, but they are not always read correctly! I will remove Unicode characters for line splits (\\n) and also remove the addresses of writers that are always at the end of the poems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c0f49-b3b8-4a2d-8b16-61f292422c60",
   "metadata": {},
   "source": [
    "## Preprocess Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f569a7-f59c-49c3-b3d5-6859cb6408d2",
   "metadata": {},
   "source": [
    "#### Remove unicode character for line splits (\\n) from each Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5bc4dc-c7c9-48fa-ae9c-14691705e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    for j in range(len(df['Text'][i])):\n",
    "            df['Text'][i][j]=df['Text'][i][j].replace('\\n',\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b215487-ab9e-47bb-8580-dbd9d6ef7158",
   "metadata": {},
   "source": [
    "#### Remove Last lines of each poem; This is the address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187c1a21-fa49-49a8-9835-64e56cd07075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x:  np.delete(x,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c1b44-34d0-4602-95be-f8540d564e38",
   "metadata": {},
   "source": [
    "Now let us examine these two texts again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3982302-a717-4e53-965c-f17a883eb631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рдмреЛрд▓реНрджрд╛ рд╣реЗрд░реНрди рд╣реБрдиреЗ рдмрд╕реЗ рдкрд░рдкрд░реИ рдХрд╕реНрд▓реЗ рдмрдирд╛рдпреЛ рдХреБрдиреА'\n",
      " 'рдЦреЛрд▓реНрджрд╛ рд╡рд┐рд╢реНрд╡ рд╕рдмреИ рдЫ рд╕реБрдиреНрди рд╕рдХрд┐рдиреЗ рд░рд╛рдЦреЗрд░\\xa0рдпрд╛рдиреНрддреНрд░рд┐рдХреН рдзреНрд╡рдирд┐'\n",
      " 'рдЬрд╕реНрддреИ рд╕рдЩреНрдХрдЯрдорд╛ рдмрд╕реЗрд░ рдШрд░рдорд╛ рдЪрд┐рдиреНрддрд╛ рдЫ рдлреЗрд╕реНрдмреВрдХрдХреЛ'\n",
      " 'рд╕рд╛рд░реИ рдХрд╖реНрдЯ рдкрд░реЗ рднрдП рд╕рд░рд▓рддрд╛ рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рдзреЗрд░реИ рдЪрд┐рдиреНрддрди рдЫрдиреН рдЧрд░реЗ рдорди рдкрд░реЗ рд▓рд╛рдЧреНрджреИрди рдкреИрд╕рд╛ рдЕрдирд┐'\n",
      " 'рдмрд╛рдБрдбреА рд╣реЗрд░реНрди рд╕рдХрд┐рдиреНрдЫ рд░реЗ рдорди рдЧрд░реЗ рд╕реЗрдпрд░реН рдЧрд░реЗрд░реИ рдкрдирд┐редред'\n",
      " 'рдпреЛрдЧрд╛ рдзреНрдпрд╛рди рдЧрд░реЗ рдЦрд┐рдЪреЗрд░ рднрд┐рдбрд┐рдпреЛ рд╣рд╛рд▓реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рднреЛ'\n",
      " 'рдЖрдорд╛, рджрд╛рдЬреБ, рджрд┐рджреА рд░ рднрд╛рдЗ-рдмрд╣рд┐рдиреА рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рдорд╛рдиреНрдЫреЗ рдЬрдиреНрдо рд╣реБрдБрджрд╛ рдЫ рд╣рд░реНрд╖рд┐рдд рдЙрддрд╛ рд╣рд╛рд▓реЗрд░ рдлреЛрдЯреЛ рдирд┐рдХреИ'\n",
      " 'рдзреЗрд░реИ рдкрд╛рда рдкрдвреА рдмрдиреЗрд░ рдЧрддрд┐рд▓реЛ рд╣рд╛рд▓реНрджрд╛ рдЫ рдлреЛрдЯреЛ рдард┐рдХреИред'\n",
      " 'рд░рд╛рдЬрд╛ рдпрд╛ рдЬрдирддрд╛ рд░ рд╢рд╛рд╕рдХ рд╕рдмреИ рдбреБрдмреНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рднреЛ'\n",
      " 'рдЭреБрдкреНрд░реЛрдорд╛ рдШрд░рдорд╛ рдмрд╕реЗ рд╕рд╣рд░рдорд╛ рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рд▓рд╛рдЧреНрджрд╛ рднреЛрдХ рдЙрддрд╛ рдХрд┐рдиреЗрд░ рдорд╕рд┐рдиреЛ рд╣рд╛рд▓реЗрд░ рдлреЗрд╕реНрдмреВрдХрдорд╛'\n",
      " 'рдЦрд╛рдиреНрдЫрдиреН рдЭрдЯреНрдЯ рдХрд┐рдиреА рдЧрдИ рдЭрдЯрдкрдЯреА рдорд╛рдиреНрдЫреЗ рдд рд╣реЛрдЯреЗрд▓рдорд╛ред'\n",
      " 'рднрд╛рдиреНрд╕рд╛ рднрд╛рдд рд▓рд┐рдЯреЛ рдЪрдврд╛рдЙрдиреБ рдЕрдШреА\\xa0рд╣рд╛рд▓реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХрднреЛ,рдЖрдзрд╛ рдШрдгреНрдЯ рдирднреИ рдмрд╕реЗрд░ рдЕрд▓рд┐рдмреЗрд░реН рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " ',' 'рдХрд╕реНрд▓реЗ рдХреЗ рдЧрд╣рдирд╛ рдХрд┐рдиреЗ рдкрд╕рд▓рдорд╛ рдкреИрд╕рд╛ рддрд┐рд░реЗрдЫрдиреН рдХрддрд┐'\n",
      " 'рдмрд╛рд▓реА рдЦреЗрдд рдЦрд┐рдЪреА рдмрддрд╛рдЙрдБрдЫ рдЫрд┐рдЯреЛ рдХреЗрдХреЗ рднрдпреЛ рдЙрдиреНрдирддрд┐ред'\n",
      " 'рдХреЛрджрд╛рд▓реЛ рд╣рдБрд╕рд┐рдпрд╛ рдЪрд▓рд╛рдЙрдиреБ рдЕрдШреА рдлреЗрд░реЗрд░ рдлреЗрд╕реНрдмреВрдХрдХреЛ'\n",
      " 'рдмрд╛рдБрдЭреЛ рдЦрдиреНрди рдкрд░реЗ рдЪрд┐рдпрд╛ рджрд┐рдиреБрдкрд░реЗ рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рдЬрд╛рдБрджрд╛ рдмрд╛рдереНрд░реБрдордорд╛ рдЪрд▓рд╛рдЙрдиреБ рдмрд╕реА рднрд╛рдиреНрд╕рд╛ рд░ рдХреЛрдард╛ рдкрд┐рдБрдбреА'\n",
      " 'рдкреВрдЬрд╛ рдкрд╛рда рднреБрд▓реА рдмрд┐рд╣рд╛рди рджрд┐рдирдорд╛ рдлреЗрд╕реНрдмреВрдХ рд╣рд╛рддреНрдорд╛ рдмрд┐рдбреАред'\n",
      " 'рдлреЛрдЯреЛ рд╣реЗрд░реНрдиреБ рд╕реБрддреА рдЙрдареА рдкрд▓рдЩрдорд╛ рдХреЛрдЯреНрдпрд╛рдЗ рдлреЗрд╕реНрдмреВрдХрдХреЛ'\n",
      " 'рд░рд╛рддреАрдорд╛ рджрд┐рдирдорд╛ рдХреБрдиреИ рд╕рдордпрдорд╛ рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рдиреЗрдкрд╛рд▓реАрд╣рд░реБрд▓реЗ рдбреБрд▓реЗрд░ рдмрд╣реБрддреИ рдлреЛрдЯреЛ рдЦрд┐рдЪреЗрдХрд╛ рдерд┐рдП'\n",
      " 'рднреЗрдЯреНрджрд╛ рдЯрд╛рд╡рд░ рддреА рдмрд╕реЗрд░ рд╕рдмрд▓реЗ рдлреЗрд╕реНрдмреВрдХрдорд╛ рд╣рд╛рд▓реНрджрд┐рдПред'\n",
      " 'рдЬрд╛рдиреЗ рдорд╛рд░реНрдЧ рдХрддрд╛ рдЫ рддреНрдпреЛ рдорди рдЧрд░реА рдЦреЛрдЬреЗрд░ рдлреЗрд╕реНрдмреВрдХрдХреЛ'\n",
      " 'рдЧрд╛рдбреА рдореЛрдЯрд░рдорд╛ рдЧреБрдбреЗ\\xa0рд╕рдм рдЬрдирд╛\\xa0рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред'\n",
      " 'рд▓реМрд░реА рд╣рд╛рдд рд▓рд┐рдИ рд╕реБрддреЗрд░ рдмрд╕рдиреЗ рдЖрдБрдЦреИ рдирджреЗрдЦреНрдиреЗрд╣рд░реВ'\n",
      " 'рдЧрд╛рдБрдбреЛ рдлреЗрд╕реНрдмреБрдХрдорд╛ рдкрдХрд╛рдЙрдБрдЫ рдард┐рдЯреА рдХрд╕реНрдХреЛ рдХреБрд░рд╛ рдХреЗ рдЧрд░реМрдБред'\n",
      " 'рд▓реЛрдХреИ рддрд░реНрдЫреБ рднрдиреА рдмрдбрд╛ рдЧрдЬрдмрдХреЛ рдЦреЛрд▓реЗрд░ рдлреЗрд╕реНрдмреВрдХ рдпреЛ'\n",
      " 'рдорд╛рдиреНрдЫреЗ рдорд░реНрдиреБ рдЕрдЧреА рд╕реБрддреА рдкрд▓рдЩрдорд╛ рд╣реЗрд░реНрдиреЗ рдд рдлреЗрд╕реНрдмреВрдХ рд╣реЛредред' '' ''\n",
      " 'рдПрдбреНрд▓реЗрдб, рдЕрд╕реНрдЯреНрд░реЗрд▓рд┐рдпрд╛']\n"
     ]
    }
   ],
   "source": [
    "print(df.Text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4053813f-b3f9-4324-b774-78decb5ecf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рд╣реЛ рдо рд╣рдЬрд╛рд░реМрдБ рдЪреЛрдЯрд┐ рдкрдЯрдХ рдкрдЯрдХ рд▓реБрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдЕрдирд┐ рд╕рдпреМрдБ рдкрдЯрдХ рдардЧрд┐рдирд╕рдореНрдо рдардЧрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рднрд┐рдбрдорд╛, рдЧрдиреНрджрд╛рдЧрдиреНрджреИ рдЧрдиреНрддреАрдорд╛ рд╣рд░рд╛рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдмреЛрд▓реНрджрд╛рдмреЛрд▓реНрджреИ рдХреИрдпреМрдБ рдкрдЯрдХ рдмреЛрд▓реА рднрд╛рд╕рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдмрд╕реНрджрд╛рдмрд╕реНрджреИ рдмрд╕реЗрдХреИ рдард╛рдЙрдБрдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рд░реЛрдЧ, рднреЛрдХ рдЕрдирд┐ рдирд╛рдЩреНрдЧреЛ рд╢рд░реАрд░ рдмреБрдЭреЗрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рджреЗрд╢рдорд╛ рд╕реБрдирдЧрд╛рднрд╛ рд░ рд╕реБрдирд╛рдЦрд░реА рд░реЛрдкреНрди рдЦреЛрдЬреНрджреИ рдЧрд░реНрджрд╛ рдорди рдлрд╛рдЯреЗрдХреЛ рдорд╛рдиреНрдЫреЗ ред' ''\n",
      " 'рд╕рд╛рдБрдЪреНрдЪреИ рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдЧрд╛рдБрд╕, рдмрд╛рд╕  рд░ рдХрдкрд╛рд╕рдХреЛ рднрд┐рдЦ рддрд┐рдореАрд╕рдБрдЧ рдорд╛рдЧреНрдиреЗ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдкрдХреНрдХрд╛ рд╣реЛ, рдзреЗрд░реИрд╕рдБрдЧ рд╣рд╛рдд рдлрд┐рдБрдЬрд╛рдИ  рдорд╛рдЧреА рдЦрд╛рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рд╣реЛ, рдо рдд рдЕрд╕рдЬрд┐рд▓реЛ рд╕рдордп рд░ рдкрд░рд┐рд╡реЗрд╢рдорд╛ рднрд┐рдЬреЗрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдкреАрдбрд╛, рдорд╛рдпрд╛ рдордорддрд╛ рдЕрдирд┐ рджреБрдГрдЦ рд╕реБрдЦ рд╕рдмреИ рдмреЛрдХреЗрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рддрд░, рдЕрдЭреИ рдкрдирд┐ рдЖрдХрд╛рд╢ рдЫреБрдиреЗ рд▓рдХреНрд╖реНрдп рдмреЛрдХреЗрд░ рдЕрдШрд┐ рдмрдвреЗрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рджреЗрд╢рдорд╛ рдкрд░рд┐рд╡рд░реНрддрди рд╣реЗрд░реНрдиреЗ, рднрд┐рдЦрдХреЛ рдЛрдг рддрд┐рд░реНрдиреЗ рдЬреЛрд╕ рднрдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рдкрдЫрд╛рдбрд┐рдмрд╛рдЯ рдЫреБрд░рд╛ рд░реЛрдкреНрдиреЗ рд╕рд╛рдереАрднрдиреНрджрд╛ рдЕрдЧрд╛рдбрд┐рдмрд╛рдЯ'\n",
      " 'рдЫреБрд░рд╛ рд░реЛрдкреНрдиреЗ рджреБрд╕реНрдорди рдкреНрдпрд╛рд░реЛ рдорд╛рдиреНрдиреЗ рдорд╛рдиреНрдЫреЗред'\n",
      " 'рддреНрдпрд╕реИрд▓реЗ рд╢рд╛рди рдирджреЗрдЦрд╛рдК рддрд┐рдореА, рдо рдмрд┐рдирд╛ рдХрд╕реБрд░рдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ'\n",
      " 'рд╕рд╛рдБрдЪреНрдЪреИ рд╣реЛ, рдо рдЖрдлреНрдиреИ рджреЗрд╢рдмрд╛рдЯ рд▓рдЦреЗрдЯрд┐рдПрдХреЛ рдорд╛рдиреНрдЫреЗ ред' ',']\n"
     ]
    }
   ],
   "source": [
    "print(df.Text[87])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda707ab-eb8a-43de-8c0f-eefb545fa7b6",
   "metadata": {},
   "source": [
    "The texts are much better; the poems are readable,  but I am not interested in analyzing each line but rather in analyzing words, so I will split each poem by word and make a new column!\n",
    "After making a list of all words in a poem, I will use some filters to remove punctuations and unwanted Unicode characters! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4814686b-8e7d-4166-914f-83667df8dce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Make a new column with list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94f7778-173e-4702-8987-a528b93ddc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Words']=df['Text'].apply(lambda x: str(x).split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d10a1-8004-41e9-ac64-323cde024dd7",
   "metadata": {},
   "source": [
    "### Now Remove punctuation, unwanted Unicode characters, and empty words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a467e761-adc9-41c2-8991-39ecc27f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = ['тАУ','.','тАЭ','тАЬ','тАШ','тАЩ', '\\n', 'nn','n', 'ред','/','!!','!!!', '\"','`', '+', '\"', '?', 'тЦБ','(', '$', '@', '[', '_', \"'\", '!', ',', ':', '^', '|', ']', '=', '%', '&', '.', ')', '(', '#', '*', '', ';', '-', '}','|','\"',\n",
    "               'рее','тАФ', 'тАФтАФ', 'тАжтАж', 'тАжтАжтАжтАж', 'тАж']\n",
    "numbers=['реж','рез', 'реи','рей', 'рек', 'рел', 'рем', 'рен', 'рео', 'реп']\n",
    "unicode=['\\u200d', '\\nn', '\\\\', \"''\\n\", \"'\\n\",\"''\\n\",\"редред'\", 'u200d','xa0','ЁЯСО', 'ЁЯСН' ]\n",
    "\n",
    "to_be_removed =  punctuations+unicode+numbers\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df['Words'][i])):\n",
    "        for char in to_be_removed: \n",
    "            df['Words'][i][j]=df['Words'][i][j].replace(char,\"\")\n",
    "            \n",
    "# Remove empty words! \n",
    "for i in range(len(df)):\n",
    "    df['Words'][i]=list(filter(None, df['Words'][i]))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b296a6-3b02-4882-921e-360e70ad9083",
   "metadata": {},
   "source": [
    "\n",
    "Let's examine words in the two example poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d946b8f3-085f-486f-83c0-01c065efddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рдмреЛрд▓реНрджрд╛', 'рд╣реЗрд░реНрди', 'рд╣реБрдиреЗ', 'рдмрд╕реЗ', 'рдкрд░рдкрд░реИ', 'рдХрд╕реНрд▓реЗ', 'рдмрдирд╛рдпреЛ', 'рдХреБрдиреА', 'рдЦреЛрд▓реНрджрд╛', 'рд╡рд┐рд╢реНрд╡', 'рд╕рдмреИ', 'рдЫ', 'рд╕реБрдиреНрди', 'рд╕рдХрд┐рдиреЗ', 'рд░рд╛рдЦреЗрд░рдпрд╛рдиреНрддреНрд░рд┐рдХреН', 'рдзреНрд╡рдирд┐', 'рдЬрд╕реНрддреИ', 'рд╕рдЩреНрдХрдЯрдорд╛', 'рдмрд╕реЗрд░', 'рдШрд░рдорд╛', 'рдЪрд┐рдиреНрддрд╛', 'рдЫ', 'рдлреЗрд╕реНрдмреВрдХрдХреЛ', 'рд╕рд╛рд░реИ', 'рдХрд╖реНрдЯ', 'рдкрд░реЗ', 'рднрдП', 'рд╕рд░рд▓рддрд╛', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдзреЗрд░реИ', 'рдЪрд┐рдиреНрддрди', 'рдЫрдиреН', 'рдЧрд░реЗ', 'рдорди', 'рдкрд░реЗ', 'рд▓рд╛рдЧреНрджреИрди', 'рдкреИрд╕рд╛', 'рдЕрдирд┐', 'рдмрд╛рдБрдбреА', 'рд╣реЗрд░реНрди', 'рд╕рдХрд┐рдиреНрдЫ', 'рд░реЗ', 'рдорди', 'рдЧрд░реЗ', 'рд╕реЗрдпрд░реН', 'рдЧрд░реЗрд░реИ', 'рдкрдирд┐', 'рдпреЛрдЧрд╛', 'рдзреНрдпрд╛рди', 'рдЧрд░реЗ', 'рдЦрд┐рдЪреЗрд░', 'рднрд┐рдбрд┐рдпреЛ', 'рд╣рд╛рд▓реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рднреЛ', 'рдЖрдорд╛', 'рджрд╛рдЬреБ', 'рджрд┐рджреА', 'рд░', 'рднрд╛рдЗрдмрд╣рд┐рдиреА', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдЬрдиреНрдо', 'рд╣реБрдБрджрд╛', 'рдЫ', 'рд╣рд░реНрд╖рд┐рдд', 'рдЙрддрд╛', 'рд╣рд╛рд▓реЗрд░', 'рдлреЛрдЯреЛ', 'рдирд┐рдХреИ', 'рдзреЗрд░реИ', 'рдкрд╛рда', 'рдкрдвреА', 'рдмрдиреЗрд░', 'рдЧрддрд┐рд▓реЛ', 'рд╣рд╛рд▓реНрджрд╛', 'рдЫ', 'рдлреЛрдЯреЛ', 'рдард┐рдХреИ', 'рд░рд╛рдЬрд╛', 'рдпрд╛', 'рдЬрдирддрд╛', 'рд░', 'рд╢рд╛рд╕рдХ', 'рд╕рдмреИ', 'рдбреБрдмреНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рднреЛ', 'рдЭреБрдкреНрд░реЛрдорд╛', 'рдШрд░рдорд╛', 'рдмрд╕реЗ', 'рд╕рд╣рд░рдорд╛', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рд▓рд╛рдЧреНрджрд╛', 'рднреЛрдХ', 'рдЙрддрд╛', 'рдХрд┐рдиреЗрд░', 'рдорд╕рд┐рдиреЛ', 'рд╣рд╛рд▓реЗрд░', 'рдлреЗрд╕реНрдмреВрдХрдорд╛', 'рдЦрд╛рдиреНрдЫрдиреН', 'рдЭрдЯреНрдЯ', 'рдХрд┐рдиреА', 'рдЧрдИ', 'рдЭрдЯрдкрдЯреА', 'рдорд╛рдиреНрдЫреЗ', 'рдд', 'рд╣реЛрдЯреЗрд▓рдорд╛', 'рднрд╛рдиреНрд╕рд╛', 'рднрд╛рдд', 'рд▓рд┐рдЯреЛ', 'рдЪрдврд╛рдЙрдиреБ', 'рдЕрдШреАрд╣рд╛рд▓реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХрднреЛрдЖрдзрд╛', 'рдШрдгреНрдЯ', 'рдирднреИ', 'рдмрд╕реЗрд░', 'рдЕрд▓рд┐рдмреЗрд░реН', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдХрд╕реНрд▓реЗ', 'рдХреЗ', 'рдЧрд╣рдирд╛', 'рдХрд┐рдиреЗ', 'рдкрд╕рд▓рдорд╛', 'рдкреИрд╕рд╛', 'рддрд┐рд░реЗрдЫрдиреН', 'рдХрддрд┐', 'рдмрд╛рд▓реА', 'рдЦреЗрдд', 'рдЦрд┐рдЪреА', 'рдмрддрд╛рдЙрдБрдЫ', 'рдЫрд┐рдЯреЛ', 'рдХреЗрдХреЗ', 'рднрдпреЛ', 'рдЙрдиреНрдирддрд┐', 'рдХреЛрджрд╛рд▓реЛ', 'рд╣рдБрд╕рд┐рдпрд╛', 'рдЪрд▓рд╛рдЙрдиреБ', 'рдЕрдШреА', 'рдлреЗрд░реЗрд░', 'рдлреЗрд╕реНрдмреВрдХрдХреЛ', 'рдмрд╛рдБрдЭреЛ', 'рдЦрдиреНрди', 'рдкрд░реЗ', 'рдЪрд┐рдпрд╛', 'рджрд┐рдиреБрдкрд░реЗ', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдЬрд╛рдБрджрд╛', 'рдмрд╛рдереНрд░реБрдордорд╛', 'рдЪрд▓рд╛рдЙрдиреБ', 'рдмрд╕реА', 'рднрд╛рдиреНрд╕рд╛', 'рд░', 'рдХреЛрдард╛', 'рдкрд┐рдБрдбреА', 'рдкреВрдЬрд╛', 'рдкрд╛рда', 'рднреБрд▓реА', 'рдмрд┐рд╣рд╛рди', 'рджрд┐рдирдорд╛', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣рд╛рддреНрдорд╛', 'рдмрд┐рдбреА', 'рдлреЛрдЯреЛ', 'рд╣реЗрд░реНрдиреБ', 'рд╕реБрддреА', 'рдЙрдареА', 'рдкрд▓рдЩрдорд╛', 'рдХреЛрдЯреНрдпрд╛рдЗ', 'рдлреЗрд╕реНрдмреВрдХрдХреЛ', 'рд░рд╛рддреАрдорд╛', 'рджрд┐рдирдорд╛', 'рдХреБрдиреИ', 'рд╕рдордпрдорд╛', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдиреЗрдкрд╛рд▓реАрд╣рд░реБрд▓реЗ', 'рдбреБрд▓реЗрд░', 'рдмрд╣реБрддреИ', 'рдлреЛрдЯреЛ', 'рдЦрд┐рдЪреЗрдХрд╛', 'рдерд┐рдП', 'рднреЗрдЯреНрджрд╛', 'рдЯрд╛рд╡рд░', 'рддреА', 'рдмрд╕реЗрд░', 'рд╕рдмрд▓реЗ', 'рдлреЗрд╕реНрдмреВрдХрдорд╛', 'рд╣рд╛рд▓реНрджрд┐рдП', 'рдЬрд╛рдиреЗ', 'рдорд╛рд░реНрдЧ', 'рдХрддрд╛', 'рдЫ', 'рддреНрдпреЛ', 'рдорди', 'рдЧрд░реА', 'рдЦреЛрдЬреЗрд░', 'рдлреЗрд╕реНрдмреВрдХрдХреЛ', 'рдЧрд╛рдбреА', 'рдореЛрдЯрд░рдорд╛', 'рдЧреБрдбреЗрд╕рдм', 'рдЬрдирд╛рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рд▓реМрд░реА', 'рд╣рд╛рдд', 'рд▓рд┐рдИ', 'рд╕реБрддреЗрд░', 'рдмрд╕рдиреЗ', 'рдЖрдБрдЦреИ', 'рдирджреЗрдЦреНрдиреЗрд╣рд░реВ', 'рдЧрд╛рдБрдбреЛ', 'рдлреЗрд╕реНрдмреБрдХрдорд╛', 'рдкрдХрд╛рдЙрдБрдЫ', 'рдард┐рдЯреА', 'рдХрд╕реНрдХреЛ', 'рдХреБрд░рд╛', 'рдХреЗ', 'рдЧрд░реМрдБ', 'рд▓реЛрдХреИ', 'рддрд░реНрдЫреБ', 'рднрдиреА', 'рдмрдбрд╛', 'рдЧрдЬрдмрдХреЛ', 'рдЦреЛрд▓реЗрд░', 'рдлреЗрд╕реНрдмреВрдХ', 'рдпреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдорд░реНрдиреБ', 'рдЕрдЧреА', 'рд╕реБрддреА', 'рдкрд▓рдЩрдорд╛', 'рд╣реЗрд░реНрдиреЗ', 'рдд', 'рдлреЗрд╕реНрдмреВрдХ', 'рд╣реЛ', 'рдПрдбреНрд▓реЗрдб', 'рдЕрд╕реНрдЯреНрд░реЗрд▓рд┐рдпрд╛']\n"
     ]
    }
   ],
   "source": [
    "print(df.Words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b5bebe-8db1-4ca9-a389-089ff5afb702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рд╣реЛ', 'рдо', 'рд╣рдЬрд╛рд░реМрдБ', 'рдЪреЛрдЯрд┐', 'рдкрдЯрдХ', 'рдкрдЯрдХ', 'рд▓реБрдЯрд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдЕрдирд┐', 'рд╕рдпреМрдБ', 'рдкрдЯрдХ', 'рдардЧрд┐рдирд╕рдореНрдо', 'рдардЧрд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рднрд┐рдбрдорд╛', 'рдЧрдиреНрджрд╛рдЧрдиреНрджреИ', 'рдЧрдиреНрддреАрдорд╛', 'рд╣рд░рд╛рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдмреЛрд▓реНрджрд╛рдмреЛрд▓реНрджреИ', 'рдХреИрдпреМрдБ', 'рдкрдЯрдХ', 'рдмреЛрд▓реА', 'рднрд╛рд╕рд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдмрд╕реНрджрд╛рдмрд╕реНрджреИ', 'рдмрд╕реЗрдХреИ', 'рдард╛рдЙрдБрдмрд╛рдЯ', 'рд▓рдЦреЗрдЯрд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд╣реЛ', 'рдо', 'рдЖрдлреНрдиреИ', 'рджреЗрд╢рдмрд╛рдЯ', 'рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд░реЛрдЧ', 'рднреЛрдХ', 'рдЕрдирд┐', 'рдирд╛рдЩреНрдЧреЛ', 'рд╢рд░реАрд░', 'рдмреБрдЭреЗрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рджреЗрд╢рдорд╛', 'рд╕реБрдирдЧрд╛рднрд╛', 'рд░', 'рд╕реБрдирд╛рдЦрд░реА', 'рд░реЛрдкреНрди', 'рдЦреЛрдЬреНрджреИ', 'рдЧрд░реНрджрд╛', 'рдорди', 'рдлрд╛рдЯреЗрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд╕рд╛рдБрдЪреНрдЪреИ', 'рд╣реЛ', 'рдо', 'рдЖрдлреНрдиреИ', 'рджреЗрд╢рдмрд╛рдЯ', 'рд▓рдЦреЗрдЯрд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдЧрд╛рдБрд╕', 'рдмрд╛рд╕', 'рд░', 'рдХрдкрд╛рд╕рдХреЛ', 'рднрд┐рдЦ', 'рддрд┐рдореАрд╕рдБрдЧ', 'рдорд╛рдЧреНрдиреЗ', 'рдорд╛рдиреНрдЫреЗ', 'рдкрдХреНрдХрд╛', 'рд╣реЛ', 'рдзреЗрд░реИрд╕рдБрдЧ', 'рд╣рд╛рдд', 'рдлрд┐рдБрдЬрд╛рдИ', 'рдорд╛рдЧреА', 'рдЦрд╛рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд╣реЛ', 'рдо', 'рдд', 'рдЕрд╕рдЬрд┐рд▓реЛ', 'рд╕рдордп', 'рд░', 'рдкрд░рд┐рд╡реЗрд╢рдорд╛', 'рднрд┐рдЬреЗрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдкреАрдбрд╛', 'рдорд╛рдпрд╛', 'рдордорддрд╛', 'рдЕрдирд┐', 'рджреБрдГрдЦ', 'рд╕реБрдЦ', 'рд╕рдмреИ', 'рдмреЛрдХреЗрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рддрд░', 'рдЕрдЭреИ', 'рдкрдирд┐', 'рдЖрдХрд╛рд╢', 'рдЫреБрдиреЗ', 'рд▓рдХреНрд╖реНрдп', 'рдмреЛрдХреЗрд░', 'рдЕрдШрд┐', 'рдмрдвреЗрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рджреЗрд╢рдорд╛', 'рдкрд░рд┐рд╡рд░реНрддрди', 'рд╣реЗрд░реНрдиреЗ', 'рднрд┐рдЦрдХреЛ', 'рдЛрдг', 'рддрд┐рд░реНрдиреЗ', 'рдЬреЛрд╕', 'рднрдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рдкрдЫрд╛рдбрд┐рдмрд╛рдЯ', 'рдЫреБрд░рд╛', 'рд░реЛрдкреНрдиреЗ', 'рд╕рд╛рдереАрднрдиреНрджрд╛', 'рдЕрдЧрд╛рдбрд┐рдмрд╛рдЯ', 'рдЫреБрд░рд╛', 'рд░реЛрдкреНрдиреЗ', 'рджреБрд╕реНрдорди', 'рдкреНрдпрд╛рд░реЛ', 'рдорд╛рдиреНрдиреЗ', 'рдорд╛рдиреНрдЫреЗ', 'рддреНрдпрд╕реИрд▓реЗ', 'рд╢рд╛рди', 'рдирджреЗрдЦрд╛рдК', 'рддрд┐рдореА', 'рдо', 'рдмрд┐рдирд╛', 'рдХрд╕реБрд░рдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд╣реЛ', 'рдо', 'рдЖрдлреНрдиреИ', 'рджреЗрд╢рдмрд╛рдЯ', 'рдирд┐рдХрд╛рд▓рд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ', 'рд╕рд╛рдБрдЪреНрдЪреИ', 'рд╣реЛ', 'рдо', 'рдЖрдлреНрдиреИ', 'рджреЗрд╢рдмрд╛рдЯ', 'рд▓рдЦреЗрдЯрд┐рдПрдХреЛ', 'рдорд╛рдиреНрдЫреЗ']\n"
     ]
    }
   ],
   "source": [
    "print(df.Words[87])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614def1-8457-4290-963b-d5545d144da0",
   "metadata": {},
   "source": [
    "Almost all of the unwanted texts are now gone, and the list consists of pure words. Now we will do some simple analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720a33b-4f36-41d1-b17f-041d28fc96aa",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "I will make a word count for counting the number of words in each poem. After that, I will find three writers who wrote the longest and shortest three poems. In a literary sense, this analysis has no value. Staking words doesn't make poems; neither a short one is the best. However, in the quantitive world, finding long and short is interesting, to say the least. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702e39f-a82a-46ca-83b6-596718601706",
   "metadata": {},
   "source": [
    "#### Make a word count table and print Poets who wrote long poems! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dfd607f-0103-446e-9c69-c642c3f75009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count']=df['Words'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c3ac12-5a2d-4554-a6c5-f9a7682139f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Writers</th>\n",
       "      <th>Poems</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>рдпрддрд┐рд░рд╛рдЬ рдЕрдЬрдирдмреА</td>\n",
       "      <td>рдХреЗрд╣реА рдпрдХреНрд╖ рдкреНрд░рд╢реНрдирд╣рд░реВ</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>рдЖрдЗрддреА рд░рд╛рдИ</td>\n",
       "      <td>рдореЗрд░реЛ рдкреНрд░рд╢реНрди рдЫ</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>рд╡рд┐рд╢реНрд╡рд╛рд╕ рд▓рд╛рдорд╛</td>\n",
       "      <td>рдЬреАрд╡рдирдХреЛ рдЧреНрд░реЗрдЯрд╡рд╛рд▓ рдЙрднрд┐рдПрд░</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Writers                  Poems  word_count\n",
       "131  рдпрддрд┐рд░рд╛рдЬ рдЕрдЬрдирдмреА    рдХреЗрд╣реА рдпрдХреНрд╖ рдкреНрд░рд╢реНрдирд╣рд░реВ         795\n",
       "6        рдЖрдЗрддреА рд░рд╛рдИ          рдореЗрд░реЛ рдкреНрд░рд╢реНрди рдЫ         760\n",
       "117  рд╡рд┐рд╢реНрд╡рд╛рд╕ рд▓рд╛рдорд╛  рдЬреАрд╡рдирдХреЛ рдЧреНрд░реЗрдЯрд╡рд╛рд▓ рдЙрднрд┐рдПрд░         652"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexH=df.sort_values('word_count', axis=0, ascending=False)[0:3].index\n",
    "df.loc[indexH,['Writers','Poems','word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fbab6b-4181-4ed7-82bc-a6617f8302b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Writers</th>\n",
       "      <th>Poems</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>рдбреА. рдПрдиреН. рдХрд╛рдлреНрд▓реЗ</td>\n",
       "      <td>рд╢рд╣реАрдж рд░ рдо</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>рдореМрд╕рдореА рдвреБрдЩреНрдЧрд╛рдирд╛</td>\n",
       "      <td>рджрд╢реИрдБрдХреЛ рдпрд╛рдж</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>рдкреБрдЬрди рд░рд╛рдИ</td>\n",
       "      <td>рдЪрд┐рддреНрд░</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Writers       Poems  word_count\n",
       "56   рдбреА. рдПрдиреН. рдХрд╛рдлреНрд▓реЗ   рд╢рд╣реАрдж рд░ рдо           40\n",
       "102  рдореМрд╕рдореА рдвреБрдЩреНрдЧрд╛рдирд╛   рджрд╢реИрдБрдХреЛ рдпрд╛рдж          50\n",
       "82          рдкреБрдЬрди рд░рд╛рдИ      рдЪрд┐рддреНрд░┬а          52"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexS=df.sort_values('word_count', axis=0, ascending=True)[0:3].index\n",
    "df.loc[indexS,['Writers','Poems','word_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e159e-c566-4fee-be2f-10b57fa03cd6",
   "metadata": {},
   "source": [
    "\"рдпрддрд┐рд░рд╛рдЬ рдЕрдЬрдирдмреА\" Has an awful lot of questions! God knows how long the answers would be; I better write a book for him. \n",
    "Joke aside, let's read the shortest Poem, shall we? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90f553d1-2e98-40bf-b932-398f35b2c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['рдЙрд╕рд▓реЗ рдорд╛рдЯреЛ рдкрд┐рдпреЛ' 'рдорд╛рдЯреЛрдореИ рд░реЛрдкреНрдпреЛ рдЬрд┐рдиреНрджрдЧреА' 'рд░ рдирд┐рд░реНрднрдп'\n",
      " 'рдлреБрд▓рд╛рдпреЛ рдЬрд┐рдиреНрджрдЧреА рднрд┐рддреНрд░рдХрд╛' 'рд╣рдЬрд╛рд░ рд╕рдкрдирд╛рд╣рд░реВ' 'рдЕрдкрд╛рд░ рдореБрд╕реНрдХрд╛рдирд╣рд░реВ ред' 'рдо рдирд╛рдереБ !'\n",
      " 'рдЬрд┐рдиреНрджрдЧреАрдХреЛ рд▓рд╛рд▓рдЪрдорд╛ рдлрд╕реЗрд░' 'рд╕реНрд╡рдкреНрдирднрд┐рддреНрд░ рд╕реНрд╡рдкреНрди рд░реЛрдкреЗрдБ' 'рд░ рдмрд╛рдЯрд╛ рд▓рд╛рдЧреЗрдБ'\n",
      " 'рдо рдкрд▓рдкрд▓ рдорд░реЗрд░ рдмрд╛рдБрдЪрд┐рд░рд╣реЗрдБ' '-рдПрдХрд╛рджреЗрд╢рдХреЛ рдирд╛рдЧрд░рд┐рдХ рднрдПрдБ' 'рдК рдорд░реЗрд░ рдкрд▓рдкрд▓ рдмрд╛рдБрдЪрд┐рд░рд╣реНрдпреЛ'\n",
      " '-рдкреБрдгреНрдпрднреВрдорд┐рдХреЛ рд╢рд╣реАрдж рднрдпреЛ ред ,']\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[indexS[0],'Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678f06f-e126-4313-b549-d3d161ce0355",
   "metadata": {},
   "source": [
    "For a quantitive analyst, an analysis is not complete without a graph, so let's do one!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec25fc-dce7-4794-8695-9f301e2e8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y = 'word_count',figsize=(7,4), grid=True, ylabel='Number of words', linestyle='-',marker='o', xlabel='Poem index', label='No of words per poem')\n",
    "plt.savefig('NoWords.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33aab70-da31-448f-bd4d-73bf708faeb1",
   "metadata": {},
   "source": [
    "## Classification by writers  (Sex, Country) and Categories of Poems and creation of a new table!\n",
    "\n",
    "The Editors of the Original book defined the book's poems, writers, and categories. They divided each poem into 18 themes and categorized each poem into 5 Broad Categories. \n",
    "I got an excel sheet from the editors, and this sheet was different from the book. But we can use pandas to do some manipulations! \n",
    "\n",
    "I read the excel tables (From a sheet called Coding-old.xlsx), stripped all spaces, and matched \"Poem Names\" to get data on Poets and Poems to the existing table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30778cc5-72cf-4f12-896b-8b291df048ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=pd.read_excel('Coding-old-old.xlsx',sheet_name='This')\n",
    "A['Poem']=A['Poem'].str.strip()\n",
    "df['Poems']=df['Poems'].str.strip()\n",
    "df3 = pd.merge(df, A, left_on=\"Poems\", right_on=\"Poem\",how='inner')\n",
    "print(len(df3))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea43aa9-a7af-4d7c-a323-9a5af174e936",
   "metadata": {},
   "source": [
    "The Length of the new table is longer than the original one. There must be some problems. Let's check if there are any duplicate Poems that got copied twice! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f1de0-5f11-4116-b3ca-eeb6ac28caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "dupes = [x for x in df.Poems if x in seen or seen.add(x)] \n",
    "df3[df3.Poems.isin(dupes)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ecaf4-861a-44d1-81c3-d33f42dd735d",
   "metadata": {},
   "source": [
    "Indeed the poem titled 'рдорд╛рдиреНрдЫреЗ'is repeated. That created two duplicates! I will find out if there are two poems of the same name! If so, I will drop duplicates! I also drop some unwanted columns inherited from the old Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc77a51-6354-4d88-96e0-ba7e297841dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.drop_duplicates(subset=['Poems','Writers'], keep='first')\n",
    "df4=df4.drop(columns=['Poet','Poem', 'G/P','Broad category'])\n",
    "df4[df4.Poems=='рдорд╛рдиреНрдЫреЗ'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdaeac-3932-49f6-b9d5-bcbf22399bd7",
   "metadata": {},
   "source": [
    "Now I make a plot of Poets and Poems by classified country of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8178b8-ade8-489f-b98e-ba2ba7ba475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupby(by=['Country'],as_index=False)[df4.columns[:1]].nunique().plot(kind='bar',x='Country',ylabel='Numbers', xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ce4da-c704-416e-b69c-e1914d4b62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupby(by=['Theme'],as_index=False)[df4.columns[7]].nunique().plot(kind='bar',x='Theme')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea2ea2-1865-4150-ab00-6c5aee1a297e",
   "metadata": {},
   "source": [
    "Poems had multiple themes, and they were stored in the same column. This is not effective for programming. I will split them into primary and secondary themes. One poem has up to 4 themes\n",
    "I make new tables with themes for each poem but only included 4 themes! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db2aea-a8d3-439d-b257-e53c12e0b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "df4['ThemeTemp'] = df4['Theme'].apply(lambda x: str(x).split(\",\"))\n",
    "ThemeList=[item for sublist in df4['ThemeTemp'] for item in sublist]\n",
    "Themefrequency = collections.Counter(ThemeList)\n",
    "print('Poems were categorised in to the following themes:\\n', np.unique([item for sublist in df4['ThemeTemp'] for item in sublist]))\n",
    "len(np.unique([item for sublist in df4['ThemeTemp'] for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e7e89-1faa-4ea1-b3a9-da2b1c77d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Theme1']=df4['ThemeTemp'].apply(lambda x: x[0])\n",
    "df4['Theme2']=df4['ThemeTemp'].apply(lambda x: x[1] if len(x)>1 else 'None' )\n",
    "df4['Theme3']=df4['ThemeTemp'].apply(lambda x: x[2] if len(x)>2 else 'None' )\n",
    "df4['Theme4']=df4['ThemeTemp'].apply(lambda x: x[3] if len(x)>3 else 'None' )\n",
    "\n",
    "\n",
    "df4['Theme1']=df4['Theme1'].apply(lambda x: str(x).strip())\n",
    "df4['Theme2']=df4['Theme2'].apply(lambda x: str(x).strip())\n",
    "df4['Theme3']=df4['Theme3'].apply(lambda x: str(x).strip())\n",
    "df4['Theme4']=df4['Theme4'].apply(lambda x: str(x).strip())\n",
    "df4=df4.drop(columns=['ThemeTemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb637750-d58e-4676-a26a-9f0e1614b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupby(['Theme1', 'Theme2']).size()\n",
    "a,b=np.unique(df4[['Theme1', 'Theme2']],return_counts=True)\n",
    "plt.bar(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b650ea-14a6-41b6-9842-9c85fc6ecd20",
   "metadata": {},
   "source": [
    "These plots show Primary and Secondary theme distribution for each poem. Not all poems have a secondary theme. Therefore it isNone in Plot 2. \n",
    "Bhutanese writers are romantic; Fancy any of them? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e70dd7-010c-486a-b362-23f5e495ec47",
   "metadata": {},
   "source": [
    "\n",
    "Apart from these small categories Poems are classified into 5 Broader categories and this is in this table, So I read it and show here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce388e-bd12-4504-8ca0-66a4065425f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table=pd.read_excel('Coding-old.xlsx',sheet_name='CatName')\n",
    "Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2c9c4-f124-4044-b350-11e0572c223c",
   "metadata": {},
   "source": [
    "A Few mapping manipulations to create a table with Broad Categories! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8005b-5a78-4393-ae99-0ebbe114de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "APS=list(Table[Table.BigCat=='APS'].Code.values)\n",
    "BP=list(Table[Table.BigCat=='BP'].Code.values)\n",
    "SSS=list(Table[Table.BigCat=='SSS'].Code.values)\n",
    "PDM=list(Table[Table.BigCat=='PDM'].Code.values)\n",
    "NSA=list(Table[Table.BigCat=='NSA'].Code.values)\n",
    "\n",
    "\n",
    "def BroadCat(x):\n",
    "    APS=list(Table[Table.BigCat=='APS'].Code.values)\n",
    "    BP=list(Table[Table.BigCat=='BP'].Code.values)\n",
    "    SSS=list(Table[Table.BigCat=='SSS'].Code.values)\n",
    "    PDM=list(Table[Table.BigCat=='PDM'].Code.values)\n",
    "    NSA=list(Table[Table.BigCat=='NSA'].Code.values)\n",
    "    if type(x)==str:\n",
    "        x=x.strip()\n",
    "        \n",
    "    if x ==0:\n",
    "        BroadCat1='Null'\n",
    "    elif x in str(APS):\n",
    "        BroadCat1='APS'\n",
    "    elif x in str(BP):\n",
    "            BroadCat1='BP'\n",
    "    elif x in str(SSS):\n",
    "            BroadCat1='SSS'\n",
    "    elif x in str(PDM):\n",
    "            BroadCat1='PDM'\n",
    "    elif x in str(NSA):\n",
    "            BroadCat1='NSA' \n",
    "    else:\n",
    "        BroadCat1='Null'\n",
    "    return BroadCat1\n",
    "\n",
    "df4['BroadCat1']=df4['Theme1'].apply(lambda x: BroadCat(x))\n",
    "df4['BroadCat2']=df4['Theme2'].apply(lambda x: BroadCat(x))\n",
    "df4['BroadCat3']=df4['Theme3'].apply(lambda x: BroadCat(x))\n",
    "df4['BroadCat4']=df4['Theme4'].apply(lambda x: BroadCat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbd9e2-a7c4-4cc8-9e6f-cb8d2da15a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a1591-49be-4d6d-9a5c-49f83b2cbbc1",
   "metadata": {},
   "source": [
    "This Table (df4) includes information on Original Themes and Broad Categories, including Poet Information and the poem text!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d40e84d-ab92-4256-955e-cbb6138a5043",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Word analysis of the whole book \n",
    "I start by making a list of all words in the book, printing unique words, and cleaning along the way!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580cf758-85e3-43cf-9004-679c1938b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Allwords=[item for sublist in df4['Words'] for item in sublist]\n",
    "print('There are' , len(np.unique(Allwords)), 'unique words in the Book')\n",
    "print(' Most repeated 20 words: \\n', np.unique(Allwords)[1:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf408194-4fac-489c-95e1-8f8e8277bb5e",
   "metadata": {},
   "source": [
    "Oh! Where did this 'B4' Come from? Let me find out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10636b35-34cb-4770-ac0f-4067a6c3d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if ('B4' in df.Words[i]):\n",
    "        print(\"Element is in Poem \", df.loc[i,'Poems'], \" written by \",df.loc[i,'Writers'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450e177-85c1-4493-9e27-5da61961bc4e",
   "metadata": {},
   "source": [
    "Shout out to \"рд▓рдХреНрдХреА рд░рд╛рд╢рд┐\" who must have been from Sector B/4. This is an inside joke; you won't get it! It is good to understand not everything is understandable to you! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52d09b-ab48-44ed-9b94-cb907562e77e",
   "metadata": {},
   "source": [
    "#### Frequency count and WordCloud \n",
    "Let's find the most repetitive words and frequencies. I will print 50 most frequent words! \n",
    "I use a package called collections for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6d8fb-281f-4c91-9452-9916f942cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "frequency = collections.Counter(Allwords)\n",
    "mostCommon=frequency.most_common(50)\n",
    "print(mostCommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b92dd5-1df1-478d-a6f8-a20e04612cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp= pd.DataFrame.from_dict(frequency, orient='index').reset_index()\n",
    "dftemp.to_excel('wordlistAll.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd5d13-1148-4674-be41-cf3d2f0c55c9",
   "metadata": {},
   "source": [
    "## Lets do a word cloud of all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9a3ca-c711-4cb6-8dd0-67271f3d2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "font = \"Lohit-Devanagari.ttf\"\n",
    "dictionary=frequency\n",
    "wordcloud = WordCloud(width = 1000, height = 700,\n",
    "                background_color ='white',\n",
    "                min_font_size = 1, font_path= font, regexp=r\"[\\u0900-\\u097F]+// \\uFFFF\").generate_from_frequencies(dictionary)\n",
    "\n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (18, 8), facecolor = None)\n",
    "plt.imshow(wordcloud,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f3ed2-fb23-4bfb-bfa4-ea36a26cc543",
   "metadata": {},
   "source": [
    "This is as best as python can do! Apparently it has some problems with Nepali text, but that does not stop us! We will\n",
    "use [Wordcloud](https://www.wordclouds.com/#:~:text=Wordclouds.com%20is%20a%20free,manually%20in%20the%20word%20list) website to produce beautiful pictures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b9627-f87f-46ff-8926-000f9cd46362",
   "metadata": {},
   "source": [
    "# Removal of small words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770101f0-e3f2-46c1-8dbc-44171825e9aa",
   "metadata": {},
   "source": [
    "I would quantify most of this as small words. If the texts were in English, I could use some API to find words belonging to unwanted classes like all the conjunctions. We do not have that luxury in our language. There are a few python classes written; explain each of them in reference and give credit! Show how they work!\n",
    "\n",
    "We tried to use nepali_embeddings_word2vec.tx written by [Nobal B. Niraula](https://aclanthology.org/2021.repl4nlp-1.pdf) and also tried another library called Nepali_nlp written by [Sushil](https://github.com/sushil79g/Nepali_nlp)\n",
    "\n",
    "\n",
    "If you are reading this, please develop an API that reads Nepali Sabdhakosh and helps people filter words based on the Grammatical class: For Now, I continue! I could remove all words with less than two characters, but that does not make sense. As Devkota once said, small does not mean unimportant. The only option is to define own small words based on the list we have!\n",
    "\n",
    "I export the frequency list and mark the small words, and reread them to remove all small words. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90d8e7-03fa-4827-8091-c265e2e5f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame.from_dict(frequency, orient='index').reset_index()\n",
    "df3.to_excel('wordlistImp.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb5ad3-2597-4539-bfd4-43fbda92a05a",
   "metadata": {},
   "source": [
    "# Manual Removal of small words\n",
    "The word list saved above (wordlist) is manually checked, and words to remove were identified and saved as smallwords2, which has a list of small and big words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e355a-5973-45ae-a0e0-027c25012b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallword=pd.read_csv('smallwords2.csv',sep=';')\n",
    "smallwords2=smallword[smallword.Column4=='remove']\n",
    "smallwords=list(smallwords2.Column1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60d622-6cd3-490f-b80b-c21d1b89e2ee",
   "metadata": {},
   "source": [
    "## A function to remove all small words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfcf5aa-c85c-49fa-b5d2-db27ac959724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewords(word,smallwords):\n",
    "    newlist=list(set(word)-set(smallwords))\n",
    "    return newlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93724d6-cea3-4499-b4da-d6ff32388a4d",
   "metadata": {},
   "source": [
    "# After Removal of small words \n",
    "I removed all small words and saved the file as df_Final. I will do the word count of big words and quantify the remaining big words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4285596-3d36-4d70-be1b-b8d3197a3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final=df4.copy()\n",
    "df_Final['Words'] = df_Final.apply(lambda row : removewords(row['Words'],\n",
    "                                  smallwords), axis = 1)\n",
    "df_Final['word_count']=df_Final['Words'].apply(lambda x: len(x))\n",
    "df_Final['unique_big_words']=df_Final['Words'].apply(lambda x: len(np.unique(x)))\n",
    "plt.plot(df_Final['word_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90698c2-2599-41e6-bb92-64d12215377f",
   "metadata": {},
   "source": [
    "Now I use frequency and counter library to do word cloud for text where small words are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a97d39-f8ff-40ec-9d0c-9100d887e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllwordsF=[item for sublist in df_Final['Words'] for item in sublist]\n",
    "import collections\n",
    "frequency = collections.Counter(AllwordsF)\n",
    "mostCommon=frequency.most_common(50)\n",
    "print('There are' , len(np.unique(AllwordsF)), 'unique words remaining')\n",
    "print('Most common 50 remaining words are: \\n', mostCommon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2505ff1-2c9e-462f-9bde-25aab7a46b5f",
   "metadata": {},
   "source": [
    "### Word Cloud again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec08e9-b818-4f28-b628-66ba0dbdabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "font = \"Lohit-Devanagari.ttf\"\n",
    "dictionary=frequency\n",
    "wordcloud = WordCloud(width = 1000, height = 700,\n",
    "                background_color ='white',\n",
    "                min_font_size = 1, font_path= font, regexp=r\"[\\u0900-\\u097F]+// \\uFFFF\").generate_from_frequencies(dictionary)\n",
    "\n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (18, 8), facecolor = None)\n",
    "plt.imshow(wordcloud,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f285419-a34e-461f-99eb-4abf3a360447",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1eda5-b2f1-441c-a2a6-ff7d29b77b6a",
   "metadata": {},
   "source": [
    "# Assigning Categories to each Words\n",
    "\n",
    "Each of 973 unique words that remained after cleaning was assigned manually into 181 codes and further into 18 different thematic categories. The categories are the same as the original thematic categories assigned by the Editors of the book. Unlike original qualitative categorization, here we classify words instead of poems into a category. An Excel sheet called (Coding-with-sub-categories-codes.xlsx) includes manual categorization. \n",
    "\n",
    "In the code, I read the excel sheet with word categories and manipulated the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31deaf1-4b96-4678-9530-b9af84e9130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat=pd.read_excel('Coding-with-sub-categories-codes.xlsx')\n",
    "Cat=Cat.iloc[:,:4]\n",
    "Cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a79c8b-dd9d-455b-9f6c-e750ee6b8567",
   "metadata": {},
   "source": [
    "# Show the distribution of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3abaa9-63ba-4ef6-9ddb-f638d98a9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA=Cat.groupby(by=['Codes'],as_index=False)[Cat.columns[1]].sum()\n",
    "AA.sort_values(by ='Frequency',ascending=False)[:30].plot(x='Codes',y='Frequency',kind='bar',color='green',grid=True,figsize=(10,5), ylabel='Frequency')\n",
    "plt.savefig('Histo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a513692-8ffc-457f-a6a7-3692d6597fef",
   "metadata": {},
   "source": [
    "# Determination of Poem Theme Based on Word Categories\n",
    "Now I will read each Big Word of each poem and classify them into Thematic categories based on the manually created excel table. \n",
    "I count the two most repeated themes in each poem and assign these two most repeated themes of a Poem as the theme of that particular poem. In the mail article I have only discussed one theme\n",
    "There are a few manipulation codes that might be understood on their own. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036787c2-7174-4d65-a0d6-9093e8642723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def CatofPoem(A):\n",
    "    p=[]\n",
    "    for i in range(len(A)):\n",
    "        p.append(Cat[Cat['Words']==A[i]].loc[:,'Sub-categories'].values)\n",
    "    return p\n",
    "    \n",
    "# A function to categorise words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d49be3-8b64-4149-ad90-502296ebd7dc",
   "metadata": {},
   "source": [
    "Here, I apply CatofPoem to each poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2b074-0bee-4cca-becf-3de8e0960aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final['WordsC']=df_Final['Words'].apply(lambda x: CatofPoem(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348bda5-c07d-41db-b20b-45128f4720b7",
   "metadata": {},
   "source": [
    "From the list of Categories found in WordC, I count the most repeated two Categories and make two Themes! (In the article, only one category is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8972e7-2532-4d91-b39b-e5bfcb0ebc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindCat(x):\n",
    "    b,c =np.unique(np.array(x),return_counts=True)\n",
    "    out = b[np.argsort(-c)]\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3a4ce-0a3b-4b39-b2d9-860c65722b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindCat1(x):\n",
    "    b,c =np.unique(np.array(x),return_counts=True)\n",
    "    if c[np.argsort(-c)][2]>=4:\n",
    "        out= b[np.argsort(-c)][1]\n",
    "    else:\n",
    "        out='None'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960e974-4da4-4d63-b2b0-6b3bf102d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final['WordsUC']=df_Final['WordsC'].apply(lambda x: np.unique(np.array(x),return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cd006-d075-4e14-ac3e-d6c991208e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final['Catt1']=df_Final['WordsC'].apply(lambda x: FindCat(x))\n",
    "df_Final['Catt2']=df_Final['WordsC'].apply(lambda x: FindCat1(x))\n",
    "\n",
    "df_Final['BCatt1']=df_Final['Catt1'].apply(lambda x: BroadCat(x))\n",
    "df_Final['BCatt2']=df_Final['Catt2'].apply(lambda x: BroadCat(x))\n",
    "\n",
    "df_Final['Catt1']=df_Final['Catt1'].apply(lambda x: str(x))\n",
    "df_Final['Catt2']=df_Final['Catt2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f3eb6-85bb-4bb5-bec4-4a89c64fd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd113db-7bc5-4738-b83c-6c2e56576b39",
   "metadata": {},
   "source": [
    "This is the Final Table that has the original thematic categories and the new ones. \n",
    "The original Broad Categories and new Broad Categories are also included. \n",
    "The Table also includes the original text and important words removed after processing, along with Author info. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f80f1d-dec3-4765-acd6-d3273496e58d",
   "metadata": {},
   "source": [
    "# Machine Theme VS the Original Theme (Analysis Presented in the book) \n",
    "Here, I only compare Quantative Cattegory (Catt1) with original qualatitive Category (Up to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668dbe4c-6735-4c6b-8618-04022bebe1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_Final['Catt1']==df_Final['Theme1']\n",
    "b=df_Final['Catt1']==df_Final['Theme2']\n",
    "c=df_Final['Catt1']==df_Final['Theme3']\n",
    "d=df_Final['Catt1']==df_Final['Theme4']\n",
    "\n",
    "e=a | b\n",
    "f=c | d\n",
    "g=e | f\n",
    "df_Final['MatchT'] = df_Final.apply(lambda _: '', axis=1)\n",
    "df_Final.loc[g,'MatchT']='Yes'\n",
    "plt.plot(df_Final.MatchT)\n",
    "print(sum(df_Final.MatchT=='Yes'), 'Poems matched')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5e9fd-225b-4d53-b3c7-51b542fef311",
   "metadata": {},
   "source": [
    "The plot shows only 24 poems quantified as Catt1, had a match with original qualitative themes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af767cf6-b0d2-46a8-ae5a-7a3b0ac39d5f",
   "metadata": {},
   "source": [
    "### Comparison of Broad Categories\n",
    "I match Bcatt1 (quantitative broad Categories) with qualitative original broad themes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cfd4f-569f-4e3f-985d-326ef6e4df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_Final['BCatt1']==df_Final['BroadCat1']\n",
    "b=df_Final['BCatt1']==df_Final['BroadCat2']\n",
    "c=df_Final['BCatt1']==df_Final['BroadCat3']\n",
    "d=df_Final['BCatt1']==df_Final['BroadCat4']\n",
    "\n",
    "\n",
    "e=a | b\n",
    "f=c | d\n",
    "g=e | f\n",
    "df_Final['MatchBC'] = df_Final.apply(lambda _: '', axis=1)\n",
    "df_Final.loc[g,'MatchBC']='Yes'\n",
    "plt.plot(df_Final.MatchBC)\n",
    "print(sum(df_Final.MatchBC=='Yes'), 'Poems matched')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fc85f-7ccf-44c8-b2ef-db24ae0c90c9",
   "metadata": {},
   "source": [
    "### Finally I plot this nice Figure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe052a-4f73-48e3-8f4c-47b298481afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.treemap(df_Final, path=[ 'BCatt1', 'Catt1', 'Poems'], values='word_count',\n",
    "                  color='MatchBC', hover_data=['Poems'],\n",
    "                  color_continuous_midpoint=np.average(df_Final['word_count'], weights=df_Final['word_count']), width=1000, height=600)\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "fig.write_image(\"plot.png\",scale=6) \n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad715dad-9121-4119-baa0-19ca430fe665",
   "metadata": {},
   "source": [
    "# Further Classification if two Quantative sub and broad Categories were used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99af0f4-8c8c-4338-b720-9df37e04167a",
   "metadata": {},
   "source": [
    "### A Look at the subcategory level (1st classification and the second classification)\n",
    "The Match percentage was 45 when I only did 1 quantitative sub-category. Will this improve if I assign 2 quantitative sub and main categories? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d16da-ae9e-47dd-aeff-0c766e98ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=df_Final.groupby(by=['Theme1'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "B=df_Final.groupby(by=['Catt1'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "figure(figsize=(8, 4), dpi=80)\n",
    "plt.bar(A.Theme1,A.Writers,label='Qualatitive Classification')\n",
    "plt.bar(B.Catt1,B.Writers,width=0.5,label='Quantitative Classification')\n",
    "plt.legend()\n",
    "plt.ylabel('No. of poems')\n",
    "plt.xlabel('Sub Categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e3c8e-887a-4701-aa53-26da1cadf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=df_Final.groupby(by=['Theme2'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "B=df_Final.groupby(by=['Catt2'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "figure(figsize=(8, 4), dpi=80)\n",
    "plt.bar(A.Theme2,A.Writers,label='Qualatitive Classification')\n",
    "plt.bar(B.Catt2,B.Writers,width=0.5,label='Quantitative Classification')\n",
    "plt.legend()\n",
    "plt.ylabel('No. of poems')\n",
    "plt.xlabel('Sub Categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9deb65a-b8bb-4163-a640-d25d2d8b60b9",
   "metadata": {},
   "source": [
    "Two system look different, why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be1874-5a4c-4265-a8c3-dc86f15c17ab",
   "metadata": {},
   "source": [
    "# Machine Categories VS the Broad Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c95f9b-4a51-4168-a6e1-efaaaf2bc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=df_Final.groupby(by=['BroadCat1'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "B=df_Final.groupby(by=['BCatt1'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "\n",
    "figure(figsize=(8, 4), dpi=80)\n",
    "\n",
    "plt.bar(A.BroadCat1,A.Writers,label='Qualatitive Classification')\n",
    "plt.bar(B.BCatt1,B.Writers,width=0.5,label='Quantitative Classification')\n",
    "plt.legend()\n",
    "plt.ylabel('No. of poems')\n",
    "plt.xlabel('Main Category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69966f73-995b-40c2-a0c5-a8a2958c4e62",
   "metadata": {},
   "source": [
    "No NSA in Machine classification! \n",
    "For sake of completeness, I also plot the same for Second Broad Category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8834b50-a8fe-421a-ab40-b2ea406b2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=df_Final.groupby(by=['BroadCat2'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "B=df_Final.groupby(by=['BCatt2'],as_index=False)[df_Final.columns[:1]].nunique()\n",
    "\n",
    "figure(figsize=(8, 4), dpi=80)\n",
    "\n",
    "plt.bar(A.BroadCat2,A.Writers,label='Qualatitive Classification')\n",
    "plt.bar(B.BCatt2,B.Writers,width=0.5,label='Quantitative Classification')\n",
    "plt.legend()\n",
    "plt.ylabel('No. of poems')\n",
    "plt.xlabel('Main Category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243c86e-e14f-4e2f-af2f-eedc02676854",
   "metadata": {},
   "source": [
    "## Find How Many Poems Matched Theme!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005b496-4ea9-4b6b-b537-90a21a07663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_Final[df_Final.Theme1==df_Final.Catt1]), ' Poems Matched Primary Theme with Primary Theme (Machine)' )\n",
    "print(len(df_Final[df_Final.Theme1==df_Final.Catt2]), ' Poems Matched Primary Theme with Secondary Theme (Machine)' )\n",
    "print(len(df_Final[df_Final.Theme2==df_Final.Catt1]),  ' Poems Matched Secondary Theme with Primary  Theme (Machine)')\n",
    "print(len(df_Final[df_Final.Theme2==df_Final.Catt2]), ' Poems Matched Secondary Theme with Secondary Theme (Machine)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9404136-0da7-4f54-8ec7-e49da0f4fe8f",
   "metadata": {},
   "source": [
    "## Now Check Broad Categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a9cd9-ed3c-4770-96d3-31901ecfff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_Final.BroadCat1==df_Final.BCatt1\n",
    "b=df_Final.BroadCat1==df_Final.BCatt2\n",
    "c=df_Final.BroadCat2==df_Final.BCatt2\n",
    "d=df_Final.BroadCat2==df_Final.BCatt2\n",
    "\n",
    "e=a | b\n",
    "f=c | d\n",
    "g=e | f\n",
    "\n",
    "print(len(df_Final[df_Final.BroadCat1==df_Final.BCatt1]), ' Poems Matched 1st Broad Category with 1st Broad Category (Machine)' )\n",
    "print(len(df_Final[df_Final.BroadCat1==df_Final.BCatt2]), ' Poems Matched 1st Broad Category with 2nd Broad Category (Machine)' )\n",
    "print(len(df_Final[df_Final.BroadCat2==df_Final.BCatt1]), ' Poems Matched 2nd Broad Category with 1st Broad Category (Machine)' )\n",
    "print(len(df_Final[df_Final.BroadCat2==df_Final.BCatt2]), ' Poems Matched 2nd Broad Category with 2nd Broad Category (Machine)' )\n",
    "print(len(df_Final[g]), ' Poems Matched at least 1 Broad Category' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5441dde-8f48-44e7-9009-cf72baf2021a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "534c62f1-7ba0-4d79-8db8-76feb3fb3e27",
   "metadata": {},
   "source": [
    "So by changing the categorization, the match percentage raised a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f896c2b-1ee6-475b-b0ce-09cdf10ab33f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
